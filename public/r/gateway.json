{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "gateway",
  "title": "AI Gateway",
  "description": "AI Gateway library for managing multiple AI providers (Vercel AI Gateway, LLM Gateway, OpenRouter) with automatic fallbacks and error handling. Integrates seamlessly with AI SDK v6.",
  "dependencies": [
    "ai",
    "@llmgateway/ai-sdk-provider",
    "@openrouter/ai-sdk-provider"
  ],
  "registryDependencies": [],
  "files": [
    {
      "path": "src/registry/new-york/lib/gateway.ts",
      "content": "/**\n * AI Gateway Configuration\n * Supports Vercel AI Gateway, LLM Gateway, and OpenRouter\n */\n\nimport type { LanguageModel } from \"ai\";\nimport { createGateway } from \"ai\";\nimport { llmgateway } from \"@llmgateway/ai-sdk-provider\";\nimport { createOpenRouter } from \"@openrouter/ai-sdk-provider\";\n\nexport type GatewayProvider = \"vercel\" | \"llmgateway\" | \"openrouter\";\n\nexport interface GatewayConfig {\n\tprovider?: GatewayProvider;\n\tapiKey?: string;\n\tmodelId: string;\n}\n\nexport class GatewayError extends Error {\n\tconstructor(\n\t\tmessage: string,\n\t\tpublic provider?: GatewayProvider,\n\t\tpublic originalError?: unknown,\n\t) {\n\t\tsuper(message);\n\t\tthis.name = \"GatewayError\";\n\t}\n}\n\n/**\n * Vercel AI Gateway Configuration\n * Uses the global gateway() function from AI SDK v6\n */\nfunction createVercelGateway(modelId: string, apiKey?: string): LanguageModel {\n\tconst gatewayApiKey =\n\t\tapiKey ||\n\t\tprocess.env.VERCEL_AI_GATEWAY_API_KEY ||\n\t\tprocess.env.AI_GATEWAY_API_KEY;\n\n\tif (!gatewayApiKey) {\n\t\tthrow new GatewayError(\n\t\t\t\"Vercel AI Gateway requires VERCEL_AI_GATEWAY_API_KEY or AI_GATEWAY_API_KEY environment variable\",\n\t\t\t\"vercel\",\n\t\t);\n\t}\n\n\ttry {\n\t\t// AI SDK v6 uses createGateway() for API key-based auth.\n\t\tconst provider = createGateway({ apiKey: gatewayApiKey });\n\t\treturn provider(modelId);\n\t} catch (error) {\n\t\tthrow new GatewayError(\n\t\t\t\"Failed to initialize Vercel AI Gateway\",\n\t\t\t\"vercel\",\n\t\t\terror,\n\t\t);\n\t}\n}\n\n/**\n * LLM Gateway Configuration\n * Uses @llmgateway/ai-sdk-provider package\n */\nfunction createLLMGateway(modelId: string, apiKey?: string): LanguageModel {\n\tconst gatewayApiKey = apiKey || process.env.LLM_GATEWAY_API_KEY;\n\n\tif (!gatewayApiKey) {\n\t\tthrow new GatewayError(\n\t\t\t\"LLM Gateway requires LLM_GATEWAY_API_KEY environment variable or apiKey parameter\",\n\t\t\t\"llmgateway\",\n\t\t);\n\t}\n\n\ttry {\n\t\t// LLM Gateway uses the llmgateway() provider function\n\t\t// It automatically uses LLM_GATEWAY_API_KEY from environment\n\t\tconst typedModelId = modelId as Parameters<typeof llmgateway>[0];\n\t\treturn llmgateway(typedModelId);\n\t} catch (error) {\n\t\tthrow new GatewayError(\n\t\t\t\"Failed to initialize LLM Gateway\",\n\t\t\t\"llmgateway\",\n\t\t\terror,\n\t\t);\n\t}\n}\n\n/**\n * OpenRouter Configuration\n * Uses @openrouter/ai-sdk-provider package\n */\nfunction createOpenRouterGateway(\n\tmodelId: string,\n\tapiKey?: string,\n): LanguageModel {\n\tconst gatewayApiKey = apiKey || process.env.OPENROUTER_API_KEY;\n\n\tif (!gatewayApiKey) {\n\t\tthrow new GatewayError(\n\t\t\t\"OpenRouter requires OPENROUTER_API_KEY environment variable or apiKey parameter\",\n\t\t\t\"openrouter\",\n\t\t);\n\t}\n\n\ttry {\n\t\tconst config: {\n\t\t\tapiKey: string;\n\t\t\theaders?: Record<string, string>;\n\t\t} = {\n\t\t\tapiKey: gatewayApiKey,\n\t\t};\n\n\t\t// Optional: Add HTTP-Referer for rankings\n\t\tif (\n\t\t\tprocess.env.OPENROUTER_SITE_URL ||\n\t\t\tprocess.env.OPENROUTER_SITE_NAME\n\t\t) {\n\t\t\tconfig.headers = {};\n\t\t\tif (process.env.OPENROUTER_SITE_URL) {\n\t\t\t\tconfig.headers[\"HTTP-Referer\"] = process.env.OPENROUTER_SITE_URL;\n\t\t\t}\n\t\t\tif (process.env.OPENROUTER_SITE_NAME) {\n\t\t\t\tconfig.headers[\"X-Title\"] = process.env.OPENROUTER_SITE_NAME;\n\t\t\t}\n\t\t}\n\n\t\tconst openrouter = createOpenRouter(config);\n\t\treturn openrouter(modelId);\n\t} catch (error) {\n\t\tthrow new GatewayError(\n\t\t\t\"Failed to initialize OpenRouter\",\n\t\t\t\"openrouter\",\n\t\t\terror,\n\t\t);\n\t}\n}\n\n/**\n * Auto-detect available gateway provider\n */\nfunction detectAvailableProvider(): GatewayProvider | null {\n\tif (\n\t\tprocess.env.VERCEL_AI_GATEWAY_API_KEY ||\n\t\tprocess.env.AI_GATEWAY_API_KEY\n\t)\n\t\treturn \"vercel\";\n\tif (process.env.LLM_GATEWAY_API_KEY) return \"llmgateway\";\n\tif (process.env.OPENROUTER_API_KEY) return \"openrouter\";\n\treturn null;\n}\n\n/**\n * Create a language model with the specified gateway provider\n *\n * @example\n * ```ts\n * // Auto-detect provider from environment\n * const model = createGatewayModel({\n *   modelId: 'openai/gpt-4o'\n * });\n *\n * const result = await generateText({\n *   model,\n *   prompt: 'Hello'\n * });\n *\n * // Using specific provider\n * const model = createGatewayModel({\n *   provider: 'vercel',\n *   modelId: 'anthropic/claude-sonnet-4'\n * });\n *\n * // Using with custom API key\n * const model = createGatewayModel({\n *   provider: 'openrouter',\n *   modelId: 'openai/gpt-4o',\n *   apiKey: 'sk-or-...'\n * });\n * ```\n */\nexport function createGatewayModel(config: GatewayConfig): LanguageModel {\n\tconst { provider: specifiedProvider, modelId, apiKey } = config;\n\n\t// Auto-detect provider if not specified\n\tconst provider = specifiedProvider || detectAvailableProvider();\n\n\tif (!provider) {\n\t\tthrow new GatewayError(\n\t\t\t\"No gateway provider configured. Please set one of: VERCEL_AI_GATEWAY_API_KEY, LLM_GATEWAY_API_KEY, or OPENROUTER_API_KEY environment variable\",\n\t\t);\n\t}\n\n\tswitch (provider) {\n\t\tcase \"vercel\":\n\t\t\treturn createVercelGateway(modelId, apiKey);\n\t\tcase \"llmgateway\":\n\t\t\treturn createLLMGateway(modelId, apiKey);\n\t\tcase \"openrouter\":\n\t\t\treturn createOpenRouterGateway(modelId, apiKey);\n\t\tdefault:\n\t\t\tthrow new GatewayError(`Unknown gateway provider: ${provider}`, provider);\n\t}\n}\n\n/**\n * Get available environment variables for the current environment\n * Useful for debugging gateway configuration\n */\nexport function getGatewayEnvironment() {\n\treturn {\n\t\tvercel: {\n\t\t\thasKey: Boolean(\n\t\t\t\tprocess.env.VERCEL_AI_GATEWAY_API_KEY ||\n\t\t\t\t\tprocess.env.AI_GATEWAY_API_KEY,\n\t\t\t),\n\t\t\tkeyName: \"VERCEL_AI_GATEWAY_API_KEY | AI_GATEWAY_API_KEY\",\n\t\t},\n\t\tllmgateway: {\n\t\t\thasKey: Boolean(process.env.LLM_GATEWAY_API_KEY),\n\t\t\tkeyName: \"LLM_GATEWAY_API_KEY\",\n\t\t},\n\t\topenrouter: {\n\t\t\thasKey: Boolean(process.env.OPENROUTER_API_KEY),\n\t\t\tkeyName: \"OPENROUTER_API_KEY\",\n\t\t\tsiteUrl: process.env.OPENROUTER_SITE_URL,\n\t\t\tsiteName: process.env.OPENROUTER_SITE_NAME,\n\t\t},\n\t};\n}\n",
      "type": "registry:lib"
    },
    {
      "path": "src/registry/new-york/hooks/use-gateway-chat.ts",
      "content": "/**\n * useGatewayChat Hook\n * Simplifies integration of AI Gateway with chat components\n */\n\n\"use client\";\n\nimport { useChat as useAIChat } from \"@ai-sdk/react\";\nimport type { ChatInit, UIMessage } from \"ai\";\nimport { TextStreamChatTransport } from \"ai\";\nimport type { GatewayConfig } from \"@/registry/new-york/lib/gateway\";\n\nexport interface UseGatewayChatOptions<UI_MESSAGE extends UIMessage = UIMessage>\n\textends Omit<ChatInit<UI_MESSAGE>, \"transport\"> {\n\t/**\n\t * Gateway configuration\n\t * If not provided, will use default /api/chat endpoint\n\t */\n\tgateway?: GatewayConfig;\n\t/**\n\t * API endpoint for chat\n\t * @default \"/api/chat\"\n\t */\n\tapi?: string;\n\t/**\n\t * Additional body parameters to send with each request\n\t */\n\tbody?: Record<string, unknown>;\n\t/**\n\t * Request headers for the chat transport.\n\t */\n\theaders?: Record<string, string> | Headers;\n\t/**\n\t * Fetch implementation override.\n\t */\n\tfetch?: typeof fetch;\n\t/**\n\t * Credentials mode for the transport.\n\t */\n\tcredentials?: RequestCredentials;\n}\n\n/**\n * Hook for using AI Gateway with chat components\n *\n * @example\n * ```tsx\n * // Auto-detect provider from environment\n * const { messages, input, handleInputChange, handleSubmit } = useGatewayChat({\n *   gateway: {\n *     modelId: 'openai/gpt-4o'\n *   }\n * });\n *\n * // Specify provider explicitly\n * const chat = useGatewayChat({\n *   gateway: {\n *     provider: 'vercel',\n *     modelId: 'anthropic/claude-sonnet-4'\n *   }\n * });\n *\n * // Without gateway (custom API route)\n * const chat = useGatewayChat({\n *   api: '/api/custom-chat'\n * });\n * ```\n */\nexport function useGatewayChat<UI_MESSAGE extends UIMessage = UIMessage>(\n\toptions: UseGatewayChatOptions<UI_MESSAGE> = {},\n) {\n\tconst {\n\t\tgateway,\n\t\tapi = \"/api/chat\",\n\t\tbody,\n\t\theaders,\n\t\tfetch,\n\t\tcredentials,\n\t\t...chatOptions\n\t} = options;\n\n\tconst transport = new TextStreamChatTransport<UI_MESSAGE>({\n\t\tapi,\n\t\theaders,\n\t\tfetch,\n\t\tcredentials,\n\t\tbody: gateway\n\t\t\t? {\n\t\t\t\t\t...body,\n\t\t\t\t\tgateway,\n\t\t\t\t}\n\t\t\t: body,\n\t});\n\n\treturn useAIChat<UI_MESSAGE>({\n\t\ttransport,\n\t\t...chatOptions,\n\t});\n}\n",
      "type": "registry:hook"
    }
  ],
  "type": "registry:lib"
}